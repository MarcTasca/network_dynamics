{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebraic graph theory\n",
    "Algebraic graph theory is concerned with the study of graphs through several related matrices.\n",
    "We then need to understand how arrays are represented and can be manipulated with Python using the library NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array creation\n",
    "You can create a numpy array from a Python list or tuple using the  `array ` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([2,3,4])\n",
    "print(\"a=\", a)\n",
    "print(\"Dimension of a:\", a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `array ` transforms lists of lists into two-dimensional arrays, i.e., matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[1.5,2,3], [4,5,6]])\n",
    "print(b)\n",
    "print(\"Dimension of b:\", b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function  `zeros ` creates an array full of zeros, the function  `ones ` creates an array full of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.zeros((3, 4))) # tuple (3,4) is the shape of the zero array to be created\n",
    "print(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can create arrays whose elements space in a given range using  `arange `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first two arguments are the starting point (included) and the ending point (excluded)\n",
    "# the third argument is the step-size\n",
    "np.arange(10, 30, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or using the function `linspace` that receives as an argument the number of elements that we want to obtain in the given range, instead of the step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first two arguments are the starting and ending point (both included!), \n",
    "# third argument is the number of elements\n",
    "np.linspace( 0, 2, 9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, numpy `ndarray` can represent arrays of any dimension but we will restrict to dimension 1 (vectors) and 2 (matrices). One-dimensional arrays are printed as rows, bidimensionals as matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange(): default start value is 0, default step size is 1\n",
    "a = np.arange(6)                         # 1d array\n",
    "print(\"a:\", a, \"\\n\")\n",
    "b = np.arange(12).reshape(4,3)           # 2d array\n",
    "print(\"b: \\n\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "Arithmetic operators on arrays apply element-wise. A new array is created and filled with the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([20,30,40,50])\n",
    "print(\"a=\",a)\n",
    "# np.arange(): default start value is 0, default step size is 1, \n",
    "# so b = [0,1,2,3]\n",
    "b = np.arange( 4 )\n",
    "print(\"b=\", b)\n",
    "c = a-b\n",
    "print(\"c= a-b =\", c)\n",
    "# ** denotes the second power ^2\n",
    "print(\"b^2=\", b**2) \n",
    "print(\"10 sin(a)=\", 10*np.sin(a))\n",
    "print(\"a<35:\", a<35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The product operator `*` operates element-wise in NumPy arrays. \n",
    "The matrix product can be performed using the `@` operator or the `dot` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two numpy arrays starting from lists of lists\n",
    "A = np.array( [[1,1],   \n",
    "               [0,1]] )\n",
    "B = np.array( [[2,0],\n",
    "               [3,4]] )\n",
    "print(\"A*B= \\n\",A * B, \"\\n\")                      # elementwise product\n",
    "print(\"A@B= \\n\",A @ B, \"\\n\")                      # matrix product\n",
    "print(\"A.dot(B)=\\n\",A.dot(B))               # another matrix product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy provides familiar mathematical functions such as sin, cos, and exp. In NumPy, these are called “universal functions”(`ufunc`). Within NumPy, these functions operate elementwise on an array, producing an array as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.arange(3) # B=[0,1,2]\n",
    "np.exp(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral graph theory\n",
    "We will explore several notions from spectral graph theory by analysing the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "nx.add_cycle(G,[1,2,3,4])\n",
    "nx.add_cycle(G,[4,3,2,1])\n",
    "\n",
    "nx.draw_circular(G, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct the `weight matrix` $W$ (called also `adjacency matrix` in NetworkX), the diagonal matrix $D$, and the normalized adjacency matrix $P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "# convert W to a numpy array\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "print(\"Degrees:\",degrees, \"\\n\")\n",
    "D = np.diag(degrees)\n",
    "print(\"D: \\n\",D,\"\\n\")\n",
    "# P = D^(-1) W\n",
    "P = np.linalg.inv(D) @ W\n",
    "print(\"P: \\n\",P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the powers of the matrix $W$. Powers of $W$ have a useful interpretation in a unweighted (di)graphs, namely, $(W^n)_{ij}$ equals the number of walks of length $n$ from $i$ to $j$.\n",
    "\n",
    "The interpretation can be extended to weighted graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^2\n",
    "#power = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "power = W\n",
    "# convert W to a numpy array\n",
    "#power = power.toarray()\n",
    "power = power @ W\n",
    "print(\"W^2 =\", power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^3\n",
    "power = power @ W\n",
    "print(\"W^3 =\", power)\n",
    "\n",
    "# Note that we compute P^3 by using P^2 to save computational time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute W^10\n",
    "for n in range(3,10):\n",
    "    power = power @ W\n",
    "print(\"W^10 =\", power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The powers of $W$ still contain zero elements. Why?\n",
    "\n",
    "The reason is that the graph $G$ is periodic, as can be easily verified. There are no closed walks of odd length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is G aperiodic:\",nx.is_aperiodic(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us modify the graph to make it aperiodic, and compute again the powers of $W$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.DiGraph()\n",
    "G2.add_nodes_from(range(1,3))\n",
    "nx.add_cycle(G2,[1,2,3,4])\n",
    "nx.add_cycle(G2,[4,3,2,1])\n",
    "G2.add_edge(1,3)\n",
    "G2.add_edge(3,1)\n",
    "\n",
    "print(\"Is G2 aperiodic:\",nx.is_aperiodic(G2))\n",
    "\n",
    "nx.draw_circular(G2, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = nx.adjacency_matrix(G2)\n",
    "W2 = W2.toarray()\n",
    "\n",
    "degrees = np.sum(W2,axis=1)\n",
    "print(\"Degrees\",degrees, \"\\n\")\n",
    "\n",
    "D2 = np.diag(degrees)\n",
    "print(\"D2: \\n\",D2,\"\\n\")\n",
    "\n",
    "P2 = np.linalg.inv(D2) @ W2\n",
    "print(\"P2: \\n\",P2,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the smallest power of $W$ that does not have null elements?\n",
    "\n",
    "**Hint**: exploit the fact that in unweighted (di)graphs $(W^n)_{ij}$ is the number of walks between $i$ and $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G2.number_of_nodes()\n",
    "index = 1\n",
    "\n",
    "power = W2\n",
    "\n",
    "while nx.is_aperiodic(G2):\n",
    "    if np.count_nonzero(power) == N*N:\n",
    "        print(\"The smallest power of W with all non-zero elements is:\", index)\n",
    "        break\n",
    "    else:\n",
    "        index += 1\n",
    "        power = power @ W2\n",
    "        \n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also observe that $G$ is bipartite, while $G_2$ is not. To this end, we exploit the notion of **coloring**.\n",
    "\n",
    "A coloring is a function $\\phi$ that assigns to every node $n$ a color $\\phi(n)$ with the properties that for every pair of adjacent nodes $\\{n,m\\}$, then $\\phi(n) != \\phi(m)$\n",
    " \n",
    "**Theorem**: a graph is bipartite if and only if there exists a 2-coloring (coloring with 2 colors) defined on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct a coloring for the graph G\n",
    "color_map = []\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    if node % 2 == 1:\n",
    "        color_map.append('blue')\n",
    "    else: \n",
    "        color_map.append('red')\n",
    "        \n",
    "print(color_map)\n",
    "\n",
    "nx.draw_circular(G, node_color=color_map, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $G$ admits a coloring, $G$ is bipartite.\n",
    "Note that a 2-coloring for $G_2$ does not exist, thus $G_2$ is not bipartite. Another way to see this, is by the following theorems.\n",
    "\n",
    "**Theorem 1**: an undirected graph is bipartite if and only if all circuits have even length.\n",
    "\n",
    "We can also leverage algebraic graph theory. The following result is a consequence of Perron-Frobenius theorem.\n",
    "\n",
    "**Theorem 2**: if a graph is bipartite, then the spectrum of its normalized adjacency matrix $P$ contains $-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig(P) returns the eigenvalues (in vector w)\n",
    "# and eigenvectors (in matrix v) of P\n",
    "\n",
    "w,v = np.linalg.eig(P)\n",
    "print(\"spectrum of P:\",w)\n",
    "\n",
    "w,v = np.linalg.eig(P2)\n",
    "print(\"spectrum of P2:\",w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theorem 1 states that $G$ is bipartite and $G_2$ is not. Theorem 2 only states that $G_2$ is not bipartite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trace of the n-th power of $W$ equals the number of circuits with length $n$ in the graph ($n\\ge2$).\n",
    "\n",
    "**Question**: what is the trace of $W^3$?\n",
    "\n",
    "To answer the question, let us plot again $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.subplot(121)\n",
    "nx.draw_circular(G, with_labels=True)\n",
    "\n",
    "plt.subplot(122)\n",
    "nx.draw_circular(G2, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of length-3 circuits in G:\", np.matrix.trace(W@W@W))\n",
    "print(\"Number of length-3 circuits in G2:\", np.matrix.trace(W2@W2@W2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a new graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(1,11))\n",
    "nx.add_cycle(G,[1,2,3])\n",
    "nx.add_cycle(G,[4,5,6])\n",
    "nx.add_cycle(G,[8,9,10])\n",
    "G.add_edges_from([(4,3), (3,8), (5,7), (7,7)])\n",
    "\n",
    "# define pos according to spring layout\n",
    "# to fix nodes' positions in all graph drawings.\n",
    "# spring_layout positions nodes using Fruchterman-Reingold force-directed algorithm.\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant probability distributions\n",
    "In this section we show how to compute the invariant distributions of a graph.\n",
    "\n",
    "**Definition**: an `invariant distribution` $\\pi$ of a graph is a normalized eigenvector of $P'$ relative to eigenvalue $1$, i.e.,\n",
    "\n",
    "$$\n",
    "P' \\pi = \\pi, \\quad \\sum_i \\pi_i = 1\n",
    "$$ \n",
    "To do this, we first compute all eigenvalues and eigenvectors of $P'$ with function `np.linalg.eig()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "print(\"Degrees:\",degrees,\"\\n\")\n",
    "D = np.diag(degrees)\n",
    "print(\"D: \\n\",D,\"\\n\")\n",
    "# P = D^(-1) W\n",
    "P = np.linalg.inv(D) @ W\n",
    "print(\"P: \\n\",P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: if the graph is strongly connected, the eigenvalue 1 has multeplicity 1 (only one invariant distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the condensation graph of $G$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "nx.draw(CG, with_labels=True)\n",
    "\n",
    "print(dict(CG.nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not strongly connected, since the condensation graph has more than one node. \n",
    "\n",
    "To confirm this, we compute the spectrum of $P$, and show that the eigenvalue 1 has algebraic multeplicity greater than 1.\n",
    "\n",
    "**Remark**: multeplicity 1 of eigenvalue 1 does not imply strong connectedness of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eig(P.T) returns the eigenvalues (in vector w)\n",
    "# and eigenvectors (in matrix v) of P'\n",
    "w,v = np.linalg.eig(P.T)\n",
    "print(\"eigenvalues:\",w) # -> the 0th and 5th eigenvalues are 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two eigenvalues equal to 1 (in position 0 and 5 of `w`). We select the eigenvectors corresponding to the two occurrencies of eigenvalue 1 and we normalize them to obtain the two invariant distributions (`pi0` and `pi5`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we iterate over indices corresponding to eigenvalues 1\n",
    "# i.e. corresponding to entries of w that are equal 1:\n",
    "# for each index we extract the corresponding eigenvector in v\n",
    "# and normalize it\n",
    "\n",
    "# we use np.isclose() to compare eigenvalues to 1 to avoid\n",
    "# numerical precision errors\n",
    "for index in [i for i in range(len(G)) if np.isclose(w[i],1)]: \n",
    "    pi = v[:,index].real  # -> eigenvectors are complex but invariant distributions are real, so we convert pi to real\n",
    "    pi = pi/np.sum(pi) # normalization\n",
    "    print(\"pi\", index, \"=\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem**: the multeplicity of the eigenvalue 1 equals the number of trapping sets of the graph. Moreover, for every trapping set, there exists a dominant eigenvector (called extremal) whose support is exactly the node set of the trapping set.\n",
    "\n",
    "**Exercise**: Compute the extremal eigenvectors of G.\n",
    "\n",
    "1. Find the attractive components of G\n",
    "2. For each attractive component, construct the corresponding induced subgraph\n",
    "3. Compute the P matrix of each induced subgraph and its invariant measure\n",
    "4. Map the obtained measures back to the original graph G (by adding zeros in the appropriate positions)\n",
    "\n",
    "**Hint**: use the methods introduced in the previous notebook, and the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now we have exploited the function `numpy.linalg.eig` to compute all the eigenvalues and eigenvectors of P', and we have selected the leading ones. \n",
    "\n",
    "Another approach consists in applying an iterative method which converges to the leading eigenvector. This will be illustrated in the following weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node centralities measure the importance of the nodes of the network. Several notions of centrality may be defined, e.g.:\n",
    "\n",
    "**Degree centrality**: the centrality of a node is proportional to its degree. In digraphs, we can define both the indegree and the outdegree centrality. For instance, the indegree centrality is a measure of importance in Twitter network, since it measures the number of followers of every account.\n",
    "\n",
    "**Eigenvector centrality**: the eigenvector centrality generalizes the degree centrality. Instead of counting the number of neighbors as the degree centrality does, this centrality gives more importance to connections with more central nodes. Let $z$ denote the centrality. Thus,\n",
    "\n",
    "$$\n",
    "z_i \\propto \\sum_{j} W_{ji}z_j\n",
    "$$\n",
    "\n",
    "By normalizing $z$, and taking the proportionality factor equal to dominant eigenvalue $\\lambda_W$, we obtain $\\lambda_W z = W'z$, i.e., $z$ is the dominant eigenvector of $W$, and has non-negative components because of Perron-Frobenius theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small networks Example: Zachary's Karate Club\n",
    "Zachary's Karate Club network is a well-know network example. This is a quite small network so we can compute centralities directly. To better understand the meaning of centrality measure it is useful to visualize them by producing appropriate graph representations.\n",
    "\n",
    "Let's first load and visualize Zachary's Karate Club network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing centralities on graphs\n",
    "We can compute centralities both using NetworkX algorithms and performing iterative procedures. It is important to make sense of the centrality vectors, and a useful way to do this is by visualizing centralities on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute, for example, the degree centrality of $G$. The following code shows how to represent $G$ so that nodes size and color reflects their centrality value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree centrality\n",
    "\n",
    "# dc is a dictionary with nodes as keys and degree centralities as values\n",
    "dc = nx.degree_centrality(G) \n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         # keys of dc are nodes\n",
    "         nodelist=dc.keys(), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = [d*10000 for d in dc.values()], \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=list(dc.values()),\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat this procedure with a different measure, eigenvector centrality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eigenvector centrality\n",
    "ec = nx.eigenvector_centrality(G)\n",
    "plt.figure(1, figsize=(10,7))\n",
    "nx.draw(G, pos,\n",
    "          with_labels=True,\n",
    "          nodelist=ec.keys(),\n",
    "          # node size is proportional to eigenvector centrality\n",
    "          node_size = [d*10000 for d in ec.values()],  \n",
    "          node_color=list(ec.values()),\n",
    "          font_size=8,\n",
    "          cmap=plt.cm.Reds,\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to compare different centrality measures for the same graph and see how they are correlated. Below we visualize the correlation between degree centrality and eigenvector centrality of G:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation degree-eigenvector\n",
    "\n",
    "# x corresponds to degree centrality values\n",
    "xdata = list(dc.values()) \n",
    "# y corresponds to eigenvector centrality values\n",
    "ydata = list(ec.values()) \n",
    "\n",
    "plt.figure(1, figsize=(7,7))\n",
    "# for each node, we plot an \"+\" with coordinates equal to the values of its\n",
    "# degree and eigenvector centrality\n",
    "plt.plot(xdata,ydata, '+') \n",
    "plt.xlabel('Degree Centrality')\n",
    "plt.ylabel('Eigenvector Centrality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two centralities appear to be correlated for G. To explore this in more details it is useful to add node ids, so that we can see which are the nodes with higher or lower correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding node ids:\n",
    "\n",
    "# We define a figure and we construct two subplots: \n",
    "# on the left we plot the centralities correlation diagram\n",
    "# with node labels, on the right we draw the graph \n",
    "# with same node labels\n",
    "fig = plt.figure(1, figsize=(14,7))\n",
    "# add_subplot() returns the axes of the subplot\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for v in range(len(G)):\n",
    "    # Axes.text(x,y,s) add the text s to Axes instance (i.e., to the subplot)\n",
    "    # at location x, y. For each node v we plot \n",
    "    # node ids in position (xdata[v], ydata[v]) where xdata = list(dc.values())\n",
    "    # and ydata = list(ec.values())\n",
    "    ax1.text(x = xdata[v], y = ydata[v], s=str(v))\n",
    "# we set the limits for x and y scales\n",
    "\n",
    "ax1.set_xlim(0, 0.6)\n",
    "ax1.set_ylim(0, 0.4)\n",
    "ax1.set_xlabel('Degree Centrality')\n",
    "ax1.set_ylabel('Eigenvector Centrality')\n",
    "\n",
    "nx.draw_networkx(G, pos, ax=ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that node 11 has degree 1, while node 16 has degree 2, so $dc(16)>dc(11)$.\n",
    "\n",
    "However, node 11 is connected to node 0, which has a large value of eigenvector centrality, while node 16 is connected to nodes 5 and 6, which have smaller values of centrality. Thus, $ec(16)<ec(11)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Invariant distribution centrality**: it generalizes the eigenvector centrality by taking into account that being connected to nodes that connect to many nodes is less important than being connected to nodes that connect with a few nodes.\n",
    "\n",
    "$$\n",
    "z = P'z\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Katz centrality**: it generalizes the eigenvector centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "\n",
    "$$\n",
    "z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, it is the eigenvector centrality. If $\\beta = 1$, then $z=\\mu$.\n",
    "\n",
    "**Bonacich centrality (or Page-rank)**: it generalizes the invariant distribution centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "$$ \n",
    "x = (1-\\beta)P' x + \\beta \\mu\\,, \\quad \\beta \\in [0,1].\n",
    "$$\n",
    "\n",
    "If $\\beta = 0$, it is the invariant distribution centrality. If $\\beta = 1$, then $x=\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to compute Katz and Bonacich centralities: **direct** and **iterative**.\n",
    "We start by computing those centralities by direct methods for the Zachary's karate club graph.\n",
    "\n",
    "## Direct method (for didactic purposes)\n",
    "Direct methods consist in inverting the equation above and computing directly the centrality. Notice that\n",
    "\n",
    "1. the Katz centrality \n",
    "$ z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu $\n",
    "\n",
    "2. and Bonacich centrality \n",
    "$ z = (\\mathbf{I}-(1-\\beta)P')^{-1} \\beta \\mu $\n",
    "\n",
    "Note that the inversion can be done (if $\\beta > 0$) because the matrices $\\frac{1-\\beta}{\\lambda_W} W'$ and $(1-\\beta)P'$ have spectral radius less than 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes() \n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))\n",
    "# note that the normalization of mu does not influence z, if we consider normalized centralities\n",
    "\n",
    "# compute the largest eigenvalue of W (which is real because of Perron-Frobenius theorem)\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) \n",
    "zk = np.linalg.inv(np.diag(np.ones(N)) - W.T*(1-beta)/lambda_max) * beta @ mu\n",
    "# normalize the centrality\n",
    "zk = zk/sum(zk)\n",
    "\n",
    "print(zk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonacich (Page-rank) centrality\n",
    "Page-rank centrality is the Bonacich centrality with $\\mu=\\mathbf{1}$ and $\\beta=0.15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb = np.linalg.inv(np.diag(np.ones(N)) - P.T*(1-beta)) * beta @ mu\n",
    "zb = zb/sum(zb)\n",
    "\n",
    "# transform centralities to float\n",
    "val = [];\n",
    "for i in zb:\n",
    "    val.append(float(i))\n",
    "\n",
    "zb_list = val\n",
    "\n",
    "# sometimes it is useful to store the centralities in a dictionary\n",
    "# create a dictionary to collect the centralities, with nodes as keys and their centrality as values\n",
    "zip_iterator = zip(G.nodes(), zb_list)\n",
    "zb_dict = dict(zip_iterator)\n",
    "\n",
    "print(zb_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute centralities by networkX functions\n",
    "The function `algorithms.link_analysis.pagerank_alg.pagerank` computes the Page-rank centrality of a given network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb2_dict = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "\n",
    "# check if the centrality are normalized\n",
    "zb2 = np.array(list(zb2_dict.values()))\n",
    "print(\"Normalization:\", sum(zb2), \"\\n\")\n",
    "\n",
    "# transform values to float\n",
    "zb2_list = [];\n",
    "for i in zb2:\n",
    "    zb2_list.append(float(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Page-rank centrality computed by the inversion formula with the one computed by NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for comparison, it is convenient to use centralities as arrays\n",
    "# before comparing we ensure that the shape of the arrays is the same\n",
    "\n",
    "print(\"Shape of zb:\", zb.shape)\n",
    "print(\"Shape of zb2\", zb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is not, we reshape zb\n",
    "zb = zb.reshape(N)\n",
    "\n",
    "# now we can compute the distance\n",
    "print(\"Distance between zb and zb2:\", np.linalg.norm(zb-zb2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_components = tuple(nx.algorithms.components.attracting_components(G))\n",
    "\n",
    "for c in attr_components:\n",
    "    # construct the induced subgraph with nodes from the attractive component c\n",
    "    sG = G.subgraph(c)\n",
    "    # construct the matrix P on the subgraph\n",
    "    W = nx.adjacency_matrix(sG)\n",
    "    W = W.toarray()\n",
    "    degrees = np.sum(W,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ W\n",
    "    # find the extremal dominant eigenvector corresponding to component c\n",
    "    w,v = np.linalg.eig(P.T)\n",
    "    for index in [i for i in range(len(sG)) if np.isclose(w[i],1)]: \n",
    "        pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "        pi = pi/np.sum(pi)\n",
    "    # map pi back in the original node space\n",
    "    pi_G = np.zeros(len(G))\n",
    "    for i in range(len(sG)):\n",
    "        pi_G[list(sG.nodes)[i]-1] = pi[i] # shift by -1 because nodes are (1,...10) while vector indexes are (0,...,9)\n",
    "    print(\"pi:\", pi_G, \"\\n\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
