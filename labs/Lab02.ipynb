{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture outline\n",
    "- Iterative methods to compute centralities\n",
    "- Network flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary on centralities\n",
    "**Degree centrality**: the centrality of a node is proportional to its (out or in)degree. \n",
    "$$\n",
    "z = w\n",
    "$$\n",
    "\n",
    "**Eigenvector centrality**: it takes into account that connections to more central nodes are more important.\n",
    "\n",
    "$$\n",
    "z = \\frac{W'z}{\\lambda_W}\n",
    "$$\n",
    "\n",
    "**Invariant distribution centrality**: it generalizes the eigenvector centrality by taking into account the relative weight of connections.\n",
    "\n",
    "$$\n",
    "z = P'z\n",
    "$$\n",
    "\n",
    "**Katz centrality**: it generalizes the eigenvector centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "\n",
    "$$\n",
    "z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu \n",
    "$$\n",
    "\n",
    "**Bonacich centrality (or Page-rank)**: it generalizes the invariant distribution centrality by assuming that nodes have also an intrinsic centrality. The centrality is the sum of the intrinsic centrality and the centrality given by the network.\n",
    "$$ \n",
    "z = (1-\\beta)P' z + \\beta \\mu \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to compute Katz and Bonacich centralities: **direct** and **iterative**.\n",
    "In the last lecture we have seen how to use using NetworkX functions for computation.\n",
    "\n",
    "### Direct method\n",
    "Direct methods consist in inverting the equation above and computing directly the centrality. Notice that\n",
    "\n",
    "1. the Katz centrality \n",
    "$ z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu $\n",
    "\n",
    "2. and Bonacich centrality \n",
    "$ z = (\\mathbf{I}-(1-\\beta)P')^{-1} \\beta \\mu $\n",
    "\n",
    "Note that the inversion can be done because the matrices $\\frac{1-\\beta}{\\lambda_W} W'$ and $(1-\\beta)P'$ have spectral radius less than 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "\n",
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative methods\n",
    "The smartest way to compute Bonacich centrality (or Katz centrality) is to by iterative methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the dynamics\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = (1-\\beta)P'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The transient of the dynamics is\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "z(1) = (1-\\beta)P'z(0) + \\beta \\mu\\\\\n",
    "z(2) = (1-\\beta)^2 (P')^2 z(0) + (1-\\beta)P' \\beta \\mu + \\beta \\mu\\\\\n",
    "\\vdots\\\\\n",
    "z(t) = (1-\\beta)^t (P')^t z(0) + \\sum_{i=0}^{t-1} (1-\\beta)^i (P')^i \\beta \\mu\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The first term vanishes as $t \\to +\\infty$ because $(1-\\beta)P'$ is sub-stochastic, while the second term is a geometric sum. The dynamics thus converges to the limit\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} z(t) = (\\mathbf{I}-(1-\\beta) P')^{-1} \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which is the Bonacich centrality of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark 1**: You should never use direct ways to compute centralities if iterative algorithms are available. The iterative method is more efficient than the direct one as the order of the graph grows, since it does not involve the inversion of a matrix $N \\times N$.\n",
    "\n",
    "**Remark 2**: Note that the convergence of $z(t)$ to the Bonacich centrality holds for every initial condition $z_0$ and the limit is independent of $z_0$.\n",
    "\n",
    "**Remark 3**: Notice that the proposed method is **distributed**, i.e., the operations at single node levels do not require a complete knowledge of the network. Each node $i$ updates its state $z_i(t+1)$ by using only local information, i.e., the i-th row of $W$ and the state $z_j(t)$ of nodes $j$ that are adjacent to $j$.\n",
    "\n",
    "Let us implement the distributed method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = G.number_of_nodes()\n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))/N\n",
    "\n",
    "# arbitrary initial condition: 1/N-uniform vector of size N (initial condition does not matters)\n",
    "z_0 = np.ones((N,1))/N\n",
    "\n",
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "\n",
    "while True:\n",
    "    z_new = P.T @ z_old * (1-beta) + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zb_distr = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zb_distr = zb_distr / sum(zb_distr)\n",
    "\n",
    "print(\"Bonacich centrality: \\n\", zb_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Katz centrality\n",
    "\n",
    "For Katz centrality, consider the following dynamics:\n",
    "\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "It is easy to prove that the dynamics converges to the Katz centrality.\n",
    "\n",
    "**Remark**: notice that the proposed method is iterative (and therefore more efficient than direct method), but it is not distributed. Indeed, to perform the computation, every node needs to know $\\lambda_W$, which is a global information on the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Compute the Katz centrality of the Zachary's karate club graph by iterative methods, and compare the results with direct methods.\n",
    "\n",
    "**Hint**: use the definition of Katz centrality and same techniques as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing sensitivity of measures\n",
    "In this section we will check the dependence of centrality measures with respect to their paramenters and the sensitivity of the iterative algorithms to compute such measure with respect to the number of iterations.\n",
    "\n",
    "## The effect of parameters\n",
    "In our first experiment we analyze the dependence of Page Rank centrality on the parameter $\\alpha=1-\\beta$. We set distinct values for $\\alpha$ while we fix the number of iterations, and run Page Rank. Then we plot the resulting Page Rank values with respect to $\\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(2, figsize=(16,7))\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos, ax=ax1)\n",
    "\n",
    "# we consider values for alpha from 0 to 1 with step size 0.25\n",
    "alphas = np.arange(0, 1.25, 0.25)\n",
    "\n",
    "for alp in alphas:\n",
    "    # pagerank has parameters alpha and mu:\n",
    "    # note that alpha = 1-beta and weight parameters mu are set to 1 by default\n",
    "    pr = nx.pagerank(G, alpha=alp) \n",
    "    prval = list(pr.values())\n",
    "    ax2.plot(prval, color=np.random.rand(3), label='alpha {0:.2f}'.format(alp))\n",
    "    \n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain the previous result. Keep in mind that the parameter alpha used by `nx.pagerank` corresponds to $1-\\beta$, and the centrality $z$ satisfies\n",
    "\n",
    "$$\n",
    "z = (1-\\beta)P'z + \\beta \\mu\n",
    "$$\n",
    "\n",
    "- As $\\alpha = 0$ ($\\beta = 1$), $z = \\mu$, i.e., Bonacich is equivalent to the intrinsic centrality $\\mu$, the network does not play any role.\n",
    "\n",
    "- As $\\alpha = 1$ ($\\beta = 0$), $z = P'z$, i.e., Bonacich is equivalent to invariant distribution centrality (the intrinsic centrality is irrelevant).\n",
    "\n",
    "In between these two extreme cases there is a combination of network effects and intrinsic centrality.\n",
    "\n",
    "## Exercise##\n",
    "Repeat the analysis. This time keep $\\alpha$ fixed to 0.5 and select 3 different non-uniform vectors $\\mu$ as `personalization` parameter to `pagerank`. How do you interpret the result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The effect of iteration number\n",
    "In this section we consider a bigger network and we analyse the speed of convergence of iterative algorithms for computing centrality measures. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the political blogs network (save it as a .gml file in the working directory of this notebook) and import it as a Graph object. We check the basic properties of G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml('polblogs.gml')\n",
    "print(\"Type of G:\", type(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since G is a multigraph, we define an equivalent graph to compute the centralities (the function 'pagerank' does not work with multigraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GG = nx.Graph()\n",
    "for n, nbrs in G.adjacency():\n",
    "    # edict is a dictionary of dictionaries; \n",
    "    # the keys of edict are parallel edges from n to nbr;\n",
    "    # the values of edict are dictionary,\n",
    "    # containing attribute values of the corresponding edge\n",
    "    for nbr, edict in nbrs.items(): \n",
    "        # each edge has weight=1, so total value is just  \n",
    "        # the number of parallel edges\n",
    "        total_value = len(edict) \n",
    "        GG.add_edge(n, nbr, weight = total_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is very large, thus we cannot plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GG.number_of_nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now test the convergence speed of `nx.pagerank` algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16,7))\n",
    "\n",
    "# set 3 iteration numbers\n",
    "iters = [10,15,50]\n",
    "# define the position of the next plot in the subplot grid\n",
    "position = 1\n",
    "# create a list to collect the page rank values obtained in the three runs \n",
    "prvals = []\n",
    "\n",
    "for max_iter in iters:\n",
    "    # compute page rank\n",
    "    pr = nx.pagerank(GG, max_iter = max_iter) \n",
    "    # compute page rank values\n",
    "    prval = list(pr.values())\n",
    "    # append the result to the list\n",
    "    prvals.append(np.array(prval)) \n",
    "    # create a new sublot in the grid\n",
    "    ax = fig.add_subplot(2,2,position)\n",
    "    # plot the PR values\n",
    "    ax.plot(prval, color=np.random.rand(3), label='{0:d} iterations'.format(max_iter))\n",
    "    position+=1\n",
    "\n",
    "# add a legend which contains all labels\n",
    "# informations specified in previous plot calls\n",
    "fig.legend()  \n",
    "# we assume the values obtained with nx.pagerank()\n",
    "# with no iterations constraints as a benchmark\n",
    "benchmark = np.array(list(nx.pagerank(GG).values())) \n",
    "# we compute errors as norm of the differences wrt the benchmark\n",
    "errors = [np.linalg.norm(prval-benchmark) for prval in prvals]\n",
    "print(\"Errors:\", errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nx.pagerank` algorithm converges very fast, in 10 iterations! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Check if our iterative algorithm for computing Bonacich centrality is as good as this by performing a similar analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An interpretation of Katz (and Bonacich) centrality\n",
    "Bonacich centrality (as well as Katz centrality) can be interpreted in terms of walks on the graphs.\n",
    "We show this by an example.\n",
    "\n",
    "We shall make use of an undirected graph and Katz centrality to simplify the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.lollipop_graph(6,3)\n",
    "G.add_edges_from([(9,8),(10,8),(11,8),(12,8),(13,8)])\n",
    "\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels = True)\n",
    "\n",
    "N = len(G)\n",
    "\n",
    "# compute matrices of the graph\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# compute the largest eigenvalue of W\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider the iterative implementation of Katz centrality\n",
    "$$\n",
    "\\begin{cases} \n",
    "z(t+1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(t) + \\beta \\mu  \\\\\n",
    "z(0) = z_0.\n",
    "\\end{cases}\n",
    "$$\n",
    "with uniform $z_0$ and $\\mu$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.ones((N,1))/N\n",
    "beta = 0.15\n",
    "# initial centrality distribution\n",
    "z = np.ones((N,1))/N\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "print(\"Centralities at iteration 0:\", z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that normalizing $\\mu$ does not modify the centrality, since in\n",
    "\n",
    "$$ \n",
    "z =  (\\mathbf{I}-\\frac{1-\\beta}{\\lambda_W} W')^{-1} \\beta \\mu \n",
    "$$\n",
    "\n",
    "$\\mu$ affects the normalization of $z$ only (same for Bonacich centrality). \n",
    "\n",
    "However, the normalization of $\\mu$ affects the transient of the iteration to compute $z$. In particular, if one considers the Bonacich centrality, using $\\mu, z_0$ such that $\\mathbf{1}' \\mu = \\mathbf{1}' z_0 = \\mathbf{1}$ is preferable, since it guarantees that, if $\\mathbf{1}' z(0)=1$, then $\\mathbf{1}' z(t)=1$ for every $t$. Indeed, if $\\mathbf{1}' z(t-1)= 1$, then \n",
    "\n",
    "$$\n",
    "\\mathbf{1}' z(t) = (1-\\beta) \\mathbf{1}' P' z(t-1) + \\beta \\mathbf{1}'\\mu = (1-\\beta) \\mathbf{1}' z(t-1) + \\beta = (1-\\beta) + \\beta = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Katz centrality\n",
    "\n",
    "After 1 iteration,\n",
    "$$\n",
    "z(1) = \\frac{(1-\\beta)}{\\lambda_W}W'z(0) + \\beta \\mu,\n",
    "$$\n",
    "\n",
    "which means that the centrality of a node is the a combination of its intrinsic centrality, and the centrality of the neighbors. Since the intrinsic centrality is the same for every node, if we start with a uniform $z(0)$, $z(1)$ depends only on the degree of the node.\n",
    "\n",
    "Similar observation can be made for the Bonacich centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after 1 iteration\n",
    "z = W.T @ z * (1-beta)/lambda_max + beta * mu\n",
    "\n",
    "z_reshape = z.reshape(N)\n",
    "\n",
    "nodesize=z_reshape*7000\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = nodesize, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=z_reshape,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) \n",
    "\n",
    "print(\"Centralities at iteration 1:\", z_reshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of iterations grows, $z(n)$ takes into account also nodes at greater distance.\n",
    "\n",
    "At the equilibrium, the centrality $z^*$ can be interpreted in terms of walks as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "z^*&=\\lim_{n \\to +\\infty}z(n)=\\sum_{n = 0}^{\\infty} \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^n (W')^n \\beta \\mu \\\\\n",
    "   &= \\beta \\mu + \\frac{(1-\\beta)}{\\lambda_W} (W') \\beta \\mu + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 (W')^2 \\beta \\mu + \\cdots\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "If one considers node $i$\n",
    "\n",
    "$$\n",
    "z^*_i = \\beta \\mu_i + \\frac{(1-\\beta)}{\\lambda_W}\\beta \\sum_{j} (W')_{ij} \\mu_j + \\left(\\frac{(1-\\beta)}{\\lambda_W}\\right)^2 \\beta \\sum_{j} ((W')^2)_{ij} \\mu_j + \\cdots\n",
    "$$\n",
    "\n",
    "**Interpretation**. Since $((W')^n)_{ij}$ is the number of paths of length $n$ from $j$ to $i$, the centrality of node $i$ is the sum of:\n",
    "- its intrinsic centrality $\\mu_i$, plus \n",
    "- the intrinsic centrality of its in-neighbors, i.e., $\\sum_j W_{ji} \\mu_j$, plus \n",
    "- the intrinsic centrality of the nodes connected by paths of length 2, and so on... \n",
    "\n",
    "Longer paths have a decreasing weight due to the term $(1-\\beta)^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: which node do you expect to have a higher Katz centrality? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "\n",
    "z_0 = np.ones(N,)/N\n",
    "mu = np.ones(N,)/N\n",
    "\n",
    "# run the dynamics\n",
    "z_old = z_0\n",
    "print()\n",
    "while True:\n",
    "    z_new = W.T @ z_old * (1-beta)/lambda_max + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zk = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zk = zk/sum(zk)\n",
    "zk = zk.reshape(N)\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zk*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zk,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: how do you expect to be modified the centralities when using Bonacich instead of Katz? Focus on node 8 vs node 5.\n",
    "\n",
    "**Hint**: recall the definition of the two centralities, i.e.,\n",
    "\n",
    "- Katz: $z =  \\frac{1-\\beta}{\\lambda_W} W' z + \\beta \\mu$\n",
    "- Bonacich: $x = (1-\\beta)P' x + \\beta \\mu$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zb_dict = nx.algorithms.link_analysis.pagerank_alg.pagerank(G)\n",
    "\n",
    "# check if the centrality are normalized\n",
    "zb = np.array(list(zb_dict.values()))\n",
    "\n",
    "print(zk)\n",
    "\n",
    "plt.figure(1, figsize=(10,7))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         with_labels=True,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node size is proportional to centrality value\n",
    "         node_size = zb*7000, \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=zb,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Compute all the centralities for the this graph, plot them, and comment the results.\n",
    "\n",
    "**Hint**: use the code introduced in the lectures to compute the degree, eigenvector, Katz and Bonacich centralities. For the invariant distribution centrality use the function `np.linalg.eig()` to find the invariant distribution of $P$. Use the code introduced in the last lecture to plot the centralities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flows over networks\n",
    "In this lab we discuss how maximum admissible flows on a capacitated network are related with cuts in the network by the Max Flow - Min Cut theorem. \n",
    "\n",
    "Let us start with the definition of flows from a source 's' to a destination 't' (called terminal nodes).\n",
    "\n",
    "**Definition**: a s-t flow is a distribution such that:\n",
    "- for every non-terminal node the incoming flow equals the outcoming flow (mass conservation);\n",
    "- the outcoming flow from $s$ equals the incoming flow to $t$ (this quantity is called **throughput**).\n",
    "\n",
    "### Example\n",
    "The blue edge labels indicate the flow along the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(2,3),(1,3)])\n",
    "\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# script to draw edge labels\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'4',\n",
    "(0,2):'1',(1,2):'2',(1,3):'2',\n",
    "(2,3):'3'},font_color='blue')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the flow distribution labelled in blue is a flow from 0 to 3. Indeed,\n",
    "- for the non-terminal nodes 1 and 2, the incoming flow equals the outcoming flow;\n",
    "- the total flow outcoming from 0 equals the total flow incoming to 3 (the throughput is 5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Flow - Min Cut Theorem\n",
    "It is given a graph $G = (V, E)$ which represents a flow network and two vertices source $s$ and sink $t$ in it. Every edge $(u,v)$ has a capacity $c(u,v)$. We want to find the maximum possible flow from s to t with the following constraint:\n",
    "\n",
    "1. Flow on an edge doesn’t exceed the given capacity of the edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'2',\n",
    "(0,2):'1',(1,2):'4',(1,3):'3',\n",
    "(2,3):'2'},font_color='red')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: consider the graph above with terminal nodes 0 and 3, where the red labels denote the capacity of the edge, i.e., the maximal flow that can be sent along the edge. What is the maximal flow that can be sent from 0 to 3?\n",
    "\n",
    "**Question**: give an intuitive answer on why a flow of throughput 4 cannot be sent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition (cut of a network)**: a s-t cut of the network $G=(N,E)$ is a partition of the nodes $\\{U,U^C\\}$, such that $s \\in U$ and $t \\in U_C$.\n",
    "\n",
    "We shall see that the notion of cut is strongly related to the maximal flow that can be sent in the network. The cuts of the network above are:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$\n",
    "\n",
    "**Definition (cut capacity)**: the capacity of a cut $\\{U,U^C\\}$ is\n",
    "$$\n",
    "C_{U} = \\sum_{i \\in U}\\sum_{j \\in U^C} c(i,j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Max flow min cut Theorem**: the maximal flow that can send from $s$ to $t$ equals the minimal cut capacity among the s-t cuts of the network. \n",
    "\n",
    "**Back to the question**:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 8$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$\n",
    "\n",
    "**Answer**: the 0-3 min-cut has capacity 3, thus the maximal flow from 0 to 3 is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NetworkX has many functions useful for flow applications, e.g., `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut`, which compute the maximum throughput and the value and the node partition of a minimum cut, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the maximal flow, the edges have to be labelled with a 'capacity' label\n",
    "# we then modify the graph in such a way to include this information \n",
    "# (check the `networkx.algorithms.flow.maximum_flow` documentation for more info)\n",
    "\n",
    "G[0][1]['capacity'] = 2\n",
    "G[0][2]['capacity'] = 1\n",
    "G[1][2]['capacity'] = 4\n",
    "G[1][3]['capacity'] = 3\n",
    "G[2][3]['capacity'] = 2\n",
    "\n",
    "nx.algorithms.flow.maximum_flow(G,0,3)\n",
    "\n",
    "# maximum_flow returns the maximal throughput, plus a dictionary containing the value of the flow that goes through each edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.algorithms.flow.minimum_cut(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention in capacitated networks: two dual problems\n",
    "\n",
    "### Adversarial intervention\n",
    "**Question**: suppose you are an adversarial agent that aims at minimizing the flow that can be send from 0 to 3 by removing capacity subject to a budget constraint (or even disconnect the network). \n",
    "- Where do you remove the capacity? \n",
    "- What is the minimal capacity that you need to remove in order to disconnect the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** \n",
    "- Since the bottleneck of the flow is the min-cut of the network, the adversary should reduce the capacity of such a  cut. Thus, in this case, the adversary should reduce capacity of edges between the sets $\\{0\\}$ and the set $\\{1,2,3\\}$, which are $(0,1)$ and $(0,2)$. \n",
    "- The minimal capacity that needs to be removed equals the capacity of the min-cut of the network, which is 3.\n",
    "\n",
    "While for this network the answer could be obvious, when the network is large the algorithms `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut` are very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'2',\n",
    "(0,2):'1',(1,2):'4',(1,3):'3',\n",
    "(2,3):'2'},font_color='red')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cuts**\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 8$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner intervention\n",
    "**Question**: Suppose you are a planner that aims at maximing the flow that can be send from 0 to 3. Where do you allocate the capacity?\n",
    "\n",
    "**Answer**: you should allocate the capacity in such a way that the capacity of the mincut is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.remove_edge(0,2)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'2',(1,2):'4',(1,3):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: suppose you can allocate a capacity 4 (that can be distributed on several links). Where do you allocate it?\n",
    "\n",
    "**Solution**: first compute the capacity of the cuts:\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 2$\n",
    "\n",
    "The min-cut is $\\{0\\},\\{1,2,3\\}$, thus the capacity should be allocated on the links between these set, i.e., on $(0,1)$.\n",
    "\n",
    "Is allocating capacity 4 on $(0,1)$ optimal? NO!\n",
    "\n",
    "In such a case, the cut capacities become:\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 6$\n",
    "\n",
    "and the corresponding throughput is 4.\n",
    "\n",
    "Note instead that after allocating a capacity 2 on edge $(0,1)$, the cut capacities become\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 4$,\n",
    "\n",
    "with still a capacity 2 to be allocated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'4',(1,2):'4',(1,3):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This remaining capacity should be allocated on both the first and the last cut, so the final solution is to allocate capacity 3 on the edge $(0,1)$, and 1 on the edge $(1,3)$ or $(2,3)$, which leads to cuts\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 5$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 5$,\n",
    "\n",
    "and maximal throughput 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical example 2\n",
    "In some cases, it is possible that the capacity of two min-cuts can be increased by improving only one edge.\n",
    "Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(0,2)\n",
    "G.remove_edge(1,3)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels={(0,1):'1',(0,2):'1',(1,2):'1',\n",
    "(2,3):'3'},font_color='red')\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the maximal throughput that can be sent from 0 to 3?\n",
    "\n",
    "The answer could be given by using NetworkX functions, but we do not use it now.\n",
    "\n",
    "**Answer**: we start by computing the cut capacities:\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 2$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 2$.\n",
    "\n",
    "The maximal throughput is thus 2.\n",
    "\n",
    "**Question 2**: suppose you can allocate a capacity 1 on the network. Where do you allocate it?\n",
    "\n",
    "**Answer**: there are two mincuts, whose capacity is 2. \n",
    "- For the mincut $U=\\{0,1\\},U^C=\\{2,3\\}$,\n",
    "$$\n",
    "C_U = c(0,2) + c(1,2)\n",
    "$$ \n",
    "- For the mincut $U=\\{0\\},U^C=\\{1,2,3\\}$,\n",
    "$$\n",
    "C_U = c(0,1) + c(0,2)\n",
    "$$\n",
    "\n",
    "Note that both the capacities can be improved by adding capacity 1 to the edge $(0,2)$. By doing this, the capacity become\n",
    "\n",
    "- $U=\\{0,1,2\\},U^C=\\{3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,1\\},U^C=\\{2,3\\}$ -> $C_U = 3$\n",
    "- $U=\\{0,2\\},U^C=\\{1,3\\}$ -> $C_U = 4$\n",
    "- $U=\\{0\\},U^C=\\{1,2,3\\}$ -> $C_U = 3$,\n",
    "\n",
    "and the maximal throughput become 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, these type of considerations can be implemented algorithmically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Flow - Min Cut Theorem and Ford Fulkerson algorithm\n",
    "\n",
    "**Credits**: The code for Ford-Fulkerson Algorithm is based on material that can be found on Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is given a graph $G = (V, E)$ which represents a flow network, and two vertices source $s$ and sink $t$ in it. Every edge $(u,v)$ has a capacity $c(u,v)$. We want to find the maximum possible flow from $s$ to $t$ with the following constraints.\n",
    "\n",
    "The desired flow $f$ is constructed iteratively starting from a zero-flow vector: at each round of the algorithm $f$ is updated in such a way that the capacity and balance constraints are not violated.\n",
    "\n",
    "To do this, at each round, given the current flow vector $f$, we define the **residual network** $G_{f}(V,E_{f})$ to be the network with capacity $c_{f}(u,v)=c(u,v)-f(u,v)$. A search on the residual graph $G_f$ is performed to find an **augmenting path** (i.e., a path on the residual network with positive capacity on every edge of the path). If an augmenting path is found, this means that the current flow $f$ on that path can be increased.\n",
    "\n",
    "### Ford–Fulkerson Algorithm \n",
    "**Inputs**: a graph $G=(V,E)$, a vector of flow capacities $c = (c(u,v))_{(u,v) \\in E}$, a source node $s$, and a sink node $t$\n",
    "\n",
    "**Output**: a flow $f = (f(u,v))_{(u,v) \\in E}$ from $s$ to $t$ of maximum throughput\n",
    "\n",
    "1. $f(u,v)\\leftarrow 0$ for all edges $(u,v)$\n",
    "2. While there is a path $p$ from $s$ to $t$ in $G_{f}$, such that $c_{f}(u,v)=c(u,v)-f(u,v)>0$ for all edges $(u,v)\\in p$:\n",
    " 1. Find $c_{f}(p)=\\min\\{c_{f}(u,v):(u,v)\\in p\\}$\n",
    " 2. For each edge $(u,v)\\in p:$\n",
    "      1. $f(u,v)\\leftarrow f(u,v)+c_{f}(p)$ (Increase the flow along the path)\n",
    "      2. $f(v,u)\\leftarrow f(v,u)-c_{f}(p)$ (Impose the symmetry of the flow)\n",
    "\n",
    "Ford-Fulkerson Algorithm is called a \"method\", instead of \"algorithm\", because it does not specify univocally how to select paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: iterative Ford-Fulkerson by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(1,3),(2,3)])\n",
    "\n",
    "pos = {0: (40, 20), 1: (60, 35), 2: (60, 5), 3: (80, 20)}\n",
    "\n",
    "labels = ['0/1000','0/1000','0/1','0/1000','0/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim at finding the maximal flow from 0 to 3.\n",
    "\n",
    "The edge labels show the flow running along the edges and the capacity of the edges.\n",
    "\n",
    "We start with flow 0 on every path.\n",
    "\n",
    "0-1-2-3, 0-1-3 and 0-2-3 are augmenting paths\n",
    "\n",
    "We arbitrarly choose to add flow on 0-1-2-3.\n",
    "\n",
    "The capacity of 0-1-2-3 is the minimal capacity of the edges in the path, which is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1/1000','0/1000','1/1','0/1000','1/1000']\n",
    "\n",
    "colors = ['red','black','red','black','red']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We update flows:\n",
    "- $f(0,1) = 1$\n",
    "- $f(1,0) = -1$ (symmetry)\n",
    "- $f(2,3) = 1$\n",
    "- $f(3,2) = -1$ (symmetry)\n",
    "- $f(1,2) = 1$\n",
    "- $f(2,1) = -1$ (symmetry),\n",
    "\n",
    "We update the residual capacities $c_f(i,j) = c(i,j) - f(i,j)$ accordingly:\n",
    "- $c_f(0,1) = 1000-1 = 999$\n",
    "- $c_f(1,0) = 0-(-1) = 1$\n",
    "- $c_f(2,3) = 1000-1 = 999$\n",
    "- $c_f(3,2) = 0-(-1) = 1$\n",
    "- $c_f(1,2) = 1-1 = 0$\n",
    "- $c_f(2,1) = 0-(-1) = 1$.\n",
    "\n",
    "Note that edges $(1,0)$ and $(2,1)$, which are not in the original network, have now positive residual capacity, meaning that we can allocate some flow on them. Intuitively speaking, allocating some flow on $(2,1)$ means removing flow from $(1,2)$. Imposing the symmetry of the flow allows to remove flow after the allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to iteratively updating flows. There are three augmenting paths: 0-1-3, 0-2-3, 0-2-1-3.\n",
    "\n",
    "We arbitrarly choose to allocate flow on the path 0-2-1-3.\n",
    "\n",
    "The maximum flow that can be allocated is 1, because of the residual capacity constraint of edge  (2,1) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1/1000','1/1000','0/1','1/1000','1/1000']\n",
    "\n",
    "colors = ['black','red','red','red','black']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 1998 steps more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','1000/1000','0/1','1000/1000','1000/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no longer augmenting paths with residual capacity in the network.\n",
    "\n",
    "Thus, the resulting flows correspond to the maximal flow that can be sent from 0 to 3.\n",
    "\n",
    "The maximal throughput that can be sent from 0 to 3 is 2000. We can verify this by using NetworkX methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign feature 'capacity' to every edge, and use networkX method for maximum flow\n",
    "\n",
    "G[0][1]['capacity'] = 1000\n",
    "G[0][2]['capacity'] = 1000\n",
    "G[1][2]['capacity'] = 1\n",
    "G[1][3]['capacity'] = 1000\n",
    "G[2][3]['capacity'] = 1000\n",
    "\n",
    "nx.algorithms.flow.maximum_flow(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen, the convergence of the Ford-Fulkerson algorithm may be slow. This depends crucially on the sequence of augmenting paths that we choose. However, the algorithm is guaranteed to converge in finite steps if the capacities are rational numbers.\n",
    "\n",
    "We draw the initial graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(0,1),(0,2),(1,2),(1,3),(2,3)])\n",
    "\n",
    "pos = {0: (40, 20), 1: (60, 35), 2: (60, 5), 3: (80, 20)}\n",
    "\n",
    "labels = ['0/1000','0/1000','0/1','0/1000','0/1000']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use another sequence of augmenting paths.\n",
    "\n",
    "We start allocating flow on the path 0-1-3, with residual capacity equal to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','0/1000','0/1','1000/1000','0/1000']\n",
    "\n",
    "colors = ['red','black','black','red','black']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now only an augmenting path, which is 0-2-3, with residual capacity equal to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['1000/1000','1000/1000','0/1','1000/1000','1000/1000']\n",
    "\n",
    "colors = ['black','red','black','black','red']\n",
    "\n",
    "zip_operator = zip(G.edges(), labels)\n",
    "labels = dict(zip_operator)\n",
    "\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels = labels)\n",
    "\n",
    "nx.draw(G, pos, with_labels = True, edge_color = colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not augmenting paths in the network, thus we have found the maximal flow in only 2 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edmonds-Karp Algorithm\n",
    "The Edmonds–Karp algorithm is an implementation of Ford–Fulkerson method, where the search order to find augmenting paths is defined. A shortest path that has available capacity is found by a breadth-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "# This class represents a directed graph using adjacency matrix representation\n",
    "class Graph:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue for BFS\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue.\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            u = queue.popleft()\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # Augment the flow while there is an augmenting path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are augmenting paths from s to t\n",
    "            # now parent stores the augmenting path found by bfs\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph(W)\n",
    "\n",
    "max_flow, flow = Graph.edmonds_karp(G,0,3)\n",
    "\n",
    "print(\"The maximum flow:\", max_flow, \"\\n\")\n",
    "print(\"The flow distribution: \\n\", flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the steps of the algorithm by adding some print in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph_print:\n",
    "    # __init__ is a reseved method in python classes.\n",
    "    # In object oriented terminology, it is the constructor of the class.\n",
    "    # We define a new class 'graph' instead of using the NetworkX package.\n",
    "    def __init__(self, graph): \n",
    "        # the Graph object represents the flow network and the graph\n",
    "        # attribute will be updated by the Edmonds-Karp Algorithm to \n",
    "        # represent the residual graph.\n",
    "        # Entry [u][v] of graph array stores the capacity of link (u,v).\n",
    "        self.graph = graph  \n",
    "        # Number of nodes:\n",
    "        self.ROW = len(graph)\n",
    "\n",
    "    def bfs(self, s, t, parent):\n",
    "        \"\"\"Returns true if there is a path from source 's' to sink 't' in the\n",
    "        residual graph. Also fills parent[] to store the path \"\"\"\n",
    "        # Mark all the vertices as not visited\n",
    "        visited = [False] * (self.ROW)\n",
    "\n",
    "        # Create a double-ended queue for BFS\n",
    "        queue = collections.deque()\n",
    "\n",
    "        # Mark the source node as visited and enqueue it\n",
    "        # When visited, nodes are appended \"to the right end\" of the queue.\n",
    "        queue.append(s)\n",
    "        visited[s] = True\n",
    "\n",
    "        # Standard BFS loop\n",
    "        while queue: # while there are still elements in the queue\n",
    "            # Nodes are extracted from \"the left end\" of the queue\n",
    "            print(\"Queue:\", queue, \"\\n\")\n",
    "            u = queue.popleft()\n",
    "            print(\"Extracted node:\", u, \"\\n\")\n",
    "\n",
    "            # Get all adjacent vertices of the dequeued vertex u\n",
    "            # If an adjacent vertex has not been visited, then mark \n",
    "            # it as visited and enqueue it.\n",
    "            \n",
    "            # Enumerate() method adds a counter to an iterable\n",
    "            # to keep a count of iterations. We cycle over row\n",
    "            # u of graph array: ind is the index of the node,\n",
    "            # val is >0 if node ind is adjacent to u, i.e. if \n",
    "            # there is residual capacity on the link (u,ind),\n",
    "            # it is 0 otherwise.\n",
    "            for ind, val in enumerate(self.graph[u]): \n",
    "                if (visited[ind] == False) and (val > 0):\n",
    "                    queue.append(ind)\n",
    "                    visited[ind] = True\n",
    "                    parent[ind] = u\n",
    "            \n",
    "            print(\"Parents\", parent, \"\\n\")\n",
    "            print(\"Visited\", visited, \"\\n \\n \\n\")\n",
    "\n",
    "        # If sink is reached by BFS starting from source, then return\n",
    "        # true, else return false\n",
    "        return visited[t]\n",
    "\n",
    "    # Returns the maximum flow from s to t in the given graph\n",
    "    def edmonds_karp(self, source, sink):\n",
    "        n_iter = 1\n",
    "        print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "        # parent array is filled by bfs() and it is used \n",
    "        # to compute augmenting paths.\n",
    "        # It is initialized with the sentinel value -1\n",
    "        # If parent[j] == -1, node 'j' has not been visited yet\n",
    "        parent = [-1] * (self.ROW)\n",
    "\n",
    "        # Both max flow value and max flow vector are \n",
    "        # initialized to 0\n",
    "        max_flow = 0  \n",
    "        # initialize matrix of zeros with size ROW x ROW\n",
    "        flow = np.array([[0] * (self.ROW)] * (self.ROW))\n",
    "\n",
    "        # Augment the flow while there is a path from source to sink\n",
    "        # in the residual graph\n",
    "        while self.bfs(source, sink, parent): # the algorithm stops when there are augmenting paths from s to t\n",
    "            # now parent stores the augmenting path found by bfs\n",
    "\n",
    "            # Find the minimum residual capacity of the edges along the\n",
    "            # origin-destination path found by BFS.\n",
    "            res_capacity = float(\"Inf\")\n",
    "            # start from the endpoint of the path\n",
    "            n = sink\n",
    "            # travel the path backwards until you reach the source\n",
    "            # and update the minimal residual capacity of links\n",
    "            while n != source:\n",
    "                res_capacity = min(res_capacity, self.graph[parent[n]][n])\n",
    "                n = parent[n] \n",
    "\n",
    "            # Add the residual capacity to the maximal throughput\n",
    "            max_flow += res_capacity\n",
    "\n",
    "            # Update the flow vector by adding the residual capacity\n",
    "            # of the augmenting path to each edge in the path (to preserve\n",
    "            # symmetry, subtract it to each reverse edge).\n",
    "            # Compute the new residual network by updating\n",
    "            # the residual capacities of the edges and reverse edges\n",
    "            # along the augmenting path.\n",
    "            v = sink\n",
    "            while v != source:\n",
    "                u = parent[v]\n",
    "                flow[u][v] += res_capacity\n",
    "                flow[v][u] -= res_capacity\n",
    "                self.graph[u][v] -= res_capacity\n",
    "                self.graph[v][u] += res_capacity\n",
    "                v = parent[v]  \n",
    "            n_iter += 1\n",
    "            print(\"iteration of bfs number:\", n_iter, \"\\n\")\n",
    "            \n",
    "        return max_flow, flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([[0,1000,1000,0],[0,0,1,1000],[0,0,0,1000],[0,0,0,0]])\n",
    "G = Graph_print(W)\n",
    "\n",
    "max_flow, flow = Graph_print.edmonds_karp(G,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Networkx implements the Edmonds-Karp algorithm. \n",
    "\n",
    "The `networkx.algorithms.flow.edmonds_karp` function returns the residual network resulting after computing the maximum flow.\n",
    "\n",
    "Networkx also provides the functions `networkx.algorithms.flow.maximum_flow` and `networkx.algorithms.flow.minimum_cut` which compute the maximun throughput and  the value and the node partition of a minimum cut, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "1. Construct the graph of the example above, and assume the link capacities defined therein.\n",
    "2. Apply the above implementation of the Edmonds-Karp algorithm to find the maximum throughput between the origin and destination nodes.\n",
    "3. Compare the result to the flow found with `maximum_flow` and check that it is equal to the min-cut capacity of the graph found with `min_cut`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebraic graph theory\n",
    "Let us solve this exercise left to do in the last lecture\n",
    "\n",
    "### Exercise\n",
    "We are given the following graph G. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(range(0,10))\n",
    "nx.add_cycle(G,[0,1,2])\n",
    "nx.add_cycle(G,[3,4,5])\n",
    "nx.add_cycle(G,[7,8,9])\n",
    "G.add_edges_from([(3,2), (2,7), (4,6), (6,6)])\n",
    "\n",
    "# define pos according to spring layout\n",
    "# to fix nodes' positions in all graph drawings.\n",
    "# spring_layout positions nodes using Fruchterman-Reingold force-directed algorithm.\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G,pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the computation of the extremal eigenvectors of G.\n",
    "\n",
    "1. Find the attractive components of G\n",
    "2. For each attractive component, construct the corresponding induced subgraph\n",
    "3. Compute the P matrix of each induced subgraph and its invariant measure\n",
    "4. Map the obtained measures back to the original graph G (by adding zeros in the appropriate positions)\n",
    "\n",
    "**Hint**: use the methods introduced in the previous notebook, the code of the last lecture, and the following theorem\n",
    "\n",
    "**Theorem**: the multeplicity of the eigenvalue 1 equals the number of attractive components (or trapping sets, as defined in the lecture notes) of the graph. Moreover, for every attractive component, there exists a dominant eigenvector (called extremal) whose support is exactly the node set of the attractive component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point 1: find the attractive components by using NetworkX functions\n",
    "attr_components = tuple(nx.algorithms.components.attracting_components(G))\n",
    "\n",
    "print(attr_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in attr_components:\n",
    "    # Point 2: construct the induced subgraph with nodes from the attractive component c\n",
    "    sG = G.subgraph(c)\n",
    "    # Point 3: compute the P matrix of each induced subgraph\n",
    "    # construct the matrix P on the subgraph\n",
    "    W = nx.adjacency_matrix(sG)\n",
    "    W = W.toarray()\n",
    "    degrees = np.sum(W,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ W\n",
    "    # find the extremal dominant eigenvector corresponding to component c\n",
    "    w,v = np.linalg.eig(P.T)\n",
    "    for index in [i for i in range(len(sG)) if np.isclose(w[i],1)]: \n",
    "        pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "        pi = pi/np.sum(pi)\n",
    "    # map pi back in the original node space\n",
    "    pi_G = np.zeros(len(G))\n",
    "    for i in range(len(sG)):\n",
    "        pi_G[list(sG.nodes)[i]] = pi[i]\n",
    "    print(\"pi:\", pi_G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the matrix $P$ of the induced subgraph with node set $c$ is equivalent to the restriction of the original $P$ on the node set $c$ (except for a permutation of the nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute P on the induced subgraphs and print it\n",
    "for c in attr_components:\n",
    "    sG = G.subgraph(c)\n",
    "    # construct the matrix P on the subgraph\n",
    "    W = nx.adjacency_matrix(sG)\n",
    "    W = W.toarray()\n",
    "    degrees = np.sum(W,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ W\n",
    "    print(\"P on the subgraph c: \\n\", P, \"\\n\")\n",
    "    \n",
    "# compute the original P and print it\n",
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "print(\"The original P: \\n\", P, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due to the fact that 'c' are attractive components, thus they do not have links that connect nodes in 'c' to nodes not belonging to 'c'.\n",
    "\n",
    "Thus, $P_c$ could be obtained without recomputing the matrices of the graph $G_c$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Katz centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nx.adjacency_matrix(G)\n",
    "W = W.toarray()\n",
    "\n",
    "# compute the largest eigenvalue of W\n",
    "w,v = np.linalg.eig(W)\n",
    "w = w.real\n",
    "\n",
    "lambda_max = max(w) \n",
    "\n",
    "beta = 0.15\n",
    "mu = np.ones((N,1))\n",
    "\n",
    "z_0 = np.ones((N,1))/N\n",
    "# set a tolerance to assess convergence to the limit\n",
    "tol = 1e-5\n",
    "# evolve the dynamics\n",
    "z_old = z_0\n",
    "\n",
    "while True:\n",
    "    z_new = W.T @ z_old * (1-beta)/lambda_max + beta * mu\n",
    "    if np.linalg.norm(z_new-z_old) < tol:\n",
    "        break\n",
    "    z_old=z_new\n",
    "\n",
    "zk_approx = z_new\n",
    "\n",
    "# normalize the centrality\n",
    "zk_approx = zk_approx / sum(zk_approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise speed of convergence Bonacich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(16,7))\n",
    "\n",
    "# set 3 iteration numbers\n",
    "iters = [10,15,50]\n",
    "# define the position of the next plot in the subplot grid\n",
    "position = 1\n",
    "# create a list to collect the page rank values obtained in the three runs \n",
    "prvals = []\n",
    "\n",
    "for max_iter in iters:\n",
    "    # compute page rank\n",
    "    z_0 = np.ones((N,1))/N\n",
    "    z_old = z_0\n",
    "    \n",
    "    while True:\n",
    "        z_new = P.T @ z_old * (1-beta) + beta * mu\n",
    "        if np.linalg.norm(z_new-z_old) < tol:\n",
    "            break\n",
    "        z_old=z_new\n",
    "\n",
    "    pr = z_new\n",
    "\n",
    "    # normalize the centrality\n",
    "    prval = pr / sum(pr)\n",
    "    \n",
    "    # append the result to the list\n",
    "    prvals.append(np.array(prval)) \n",
    "    # create a new sublot in the grid\n",
    "    ax = fig.add_subplot(2,2,position)\n",
    "    # plot the PR values\n",
    "    ax.plot(prval, color=np.random.rand(3), label='{0:d} iterations'.format(max_iter))\n",
    "    position+=1\n",
    "\n",
    "# add a legend which contains all label\n",
    "# informations specified in previous plot calls\n",
    "fig.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
