{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear averaging dynamics\n",
    "In the first part of the lab we study linear averaging dynamics on graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $G=(V,E,W)$ be a weighted graph, and $x(t) \\in \\mathrm{R}^{V}$ denote the state of the nodes of the graph.\n",
    "\n",
    "The dynamics of $x(t)$ reads\n",
    "\n",
    "$$\n",
    "x(t+1) = Px(t),\n",
    "$$\n",
    "\n",
    "where $P$ is the normalized adjacency matrix.\n",
    "Among the applications, the most popular is opinion dynamics, where $x_i$ indicates the opinion of node $i$. This dynamics is known as French - De Groot.\n",
    "\n",
    "Note that we assume by convention that the opinion of node $i$ is influenced by the opinion of node $j$ if $P_{ij}>0$, i.e., the link $(i,j)$ has to be interpreted as $i$ watching $j$ and updating her opinion based on opinion of $j$.\n",
    "\n",
    "**Observation**: observe that $\\mathbf{1}$ is an equilibrium distribution, since $\\mathbf{1} = P \\mathbf{1}$ ($P$ is row-stochastic by construction), i.e., consensus distributions are equilibria of the dynamics.\n",
    "\n",
    "**Questions**: \n",
    "- what are the conditions under which the dynamics converges to an equilibrium?\n",
    "- what are the conditions under which all equilibria are consensus configurations?\n",
    "\n",
    "**Theorem**: assume that\n",
    "- its condensation graph has 1 sink;\n",
    "- the graph is aperiodic.\n",
    "\n",
    "Then,\n",
    "\n",
    "$$\n",
    "\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1},\n",
    "$$\n",
    "\n",
    "i.e., the agents get to consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why aperiodicity matters: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = {0:[0,0], 1:[0,2], 2:[2,2], 3:[2,0]}\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the graph is periodic because of every cycle has even length (the graph is bipartite and undirected, thus its period is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign initial opinion to nodes and run the dynamics\n",
    "x = np.array([1,0,1,0])\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "# plot centrality at iteration 0\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes with opinion 1 are red, nodes with opinion 0 are white.\n",
    "\n",
    "After one iteration..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ x\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) \n",
    "\n",
    "print(\"x(1):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5 iterations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = P @ P @ P @ P @ x\n",
    "\n",
    "nodecolor=x\n",
    "\n",
    "plt.figure(1, figsize=(5,3))\n",
    "# we draw the graph with same node position \"pos\" defined above\n",
    "nx.draw(G,pos,\n",
    "         nodelist=list(G.nodes()), \n",
    "         # node's color reflects centrality values (higher dc = darker color)\n",
    "         node_color=nodecolor,\n",
    "         font_size=8,\n",
    "         # node's colors are on the red scale\n",
    "         cmap=plt.cm.Reds,\n",
    "         with_labels=True) \n",
    "\n",
    "print(\"x(5):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periodicity of the graph does not allow a proper mixing of the opinions!\n",
    "\n",
    "Let us add a link to make the graph aperiodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "G.add_edge(0,2)\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run again the dynamics with same initial conditions as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,0,1,0])\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(1):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(2):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(3):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(4):\", x)\n",
    "\n",
    "x = P @ x\n",
    "print(\"x(5):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(10):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(15):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(20):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(25):\", x)\n",
    "\n",
    "x = P @ P @ P @ P @ P @ x\n",
    "print(\"x(30):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics reachs an equilibrium, which is a consensus.\n",
    "\n",
    "### Two questions\n",
    "- How fast the consensus is achieved?\n",
    "- What is the consensus value?\n",
    "\n",
    "We will answer to these questions later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 1 sink in the condensation graph: example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "G.add_edges_from([(1,2),(2,1),(1,0),(0,2),(3,2),(3,4),(4,5),(5,4),(6,4),(5,6)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many sink components does this graph have?\n",
    "\n",
    "Let us compute the condensation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condensation graph has 2 sinks. Thus, the sufficient conditions under which the dynamics converges to consensus does not hold.\n",
    "\n",
    "Let us figure out why by an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(100):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics does not reach consensus, because there are two communities of agents that do not communicate each other, and achieve consensus separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now add a link in such a way that the condensation graph has now a single sink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(6,3)\n",
    "nx.draw(G, pos, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = nx.algorithms.components.condensation(G)\n",
    "nx.draw(CG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now run the dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# define initial condition\n",
    "x = [1, 1, 0, 1, 1, 0, 0]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(199):\n",
    "    x = P @ x\n",
    "print(\"x(200):\", x, \"\\n\")\n",
    "\n",
    "for n in range(999):\n",
    "    x = P @ x\n",
    "print(\"x(1000):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now reach consensus!!\n",
    "\n",
    "## Consensus value\n",
    "\n",
    "How is the consensus value computed?\n",
    "\n",
    "Let $\\pi$ denote the normalized left dominant eigenvector of $P$, i.e., the normalized $\\pi$ such that $P' \\pi = \\pi$ (which is unique because the graph has one sink only).\n",
    "We use the fact that\n",
    "\n",
    "$$\n",
    "\\pi' x(t) = \\pi' P x(t-1) = \\pi' x(t-1),\n",
    "$$\n",
    "\n",
    "thus $\\pi' x(t)$ is constant along the dynamics. Thus,\n",
    "\n",
    "$$\n",
    "\\pi' x(0) = \\pi' \\lim_{t \\to + \\infty} x(t) = \\alpha \\pi' \\mathbf{1} = \\alpha.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thie computation above says that the consensus value $\\alpha$ is the weighted average of the initial conditions of the nodes, where the weights are given by the (unique) invariant distribution $\\pi$.\n",
    "\n",
    "Recall that $\\pi$ solving $\\pi = P' \\pi$ is also the invariant distribution centrality, thus the more a node is central the more its initial opinion affects the consensus value.\n",
    "\n",
    "Let us explore the form of $\\pi$ for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(P.T)\n",
    "\n",
    "# selects the eigenvalue 1 and print the eigenvector\n",
    "for index in [i for i in range(len(G)) if np.isclose(w[i],1)]: \n",
    "    pi = v[:,index].real  # -> eigenvectors are complex but pi is real, so we convert it to real\n",
    "    pi = pi/np.sum(pi)\n",
    "    print(\"pi\", index, \"=\", pi)\n",
    "    \n",
    "nx.draw(G,pos,with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The invariant distribution centrality is 0 for all the nodes that do not belong to the sink of the condensantion graph!\n",
    "\n",
    "This implies that the initial opinion of the nodes not belonging to the sink are negligible for the consensus value.\n",
    "\n",
    "The intuition for this is that the nodes 0, 1 and 2 do not care of the other nodes, because are not out-connected to any other node out of the component, and they reach consensus because the induced subgraph on 0,1,2 is aperiodic and strongly connected.\n",
    "Thus, their evolution is not affected by other nodes. Conversely, the other nodes update their opinion based on 2 also, thus eventually they tend to agree to the opinion of node 2 (and thus 0 and 1 as well).\n",
    "\n",
    "Let us modify the initial condition of nodes 3,4,5,6 to observe that the consensus value is not affected by this modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial condition\n",
    "x = [1, 0, 0, 80, 25, 8, 12]\n",
    "\n",
    "for n in range(99):\n",
    "    x = P @ x\n",
    "print(\"x(100):\", x, \"\\n\")\n",
    "\n",
    "for n in range(200):\n",
    "    x = P @ x\n",
    "print(\"x(300):\", x, \"\\n\")\n",
    "\n",
    "for n in range(1000):\n",
    "    x = P @ x\n",
    "print(\"x(1300):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed of convergence\n",
    "\n",
    "Let us work now for undirected (the following argument holds only for directed) connected graphs. If the graph is also aperiodic, the dynamics is guaranteed to converge to consensus.\n",
    "\n",
    "Let $\\lambda:=\\max \\{\\lambda_2,|\\lambda_n|\\}$, where $\\lambda_1 \\ge \\lambda_2 \\ge \\cdots \\ge \\lambda_n$ are the eigenvalues of $P$. Recall that $\\lambda_n \\ge -1$ by construction of $P$. \n",
    "\n",
    "It is known that the dynamics reaches consensus exponentially fast. In particular, the distance from consensus at time $t$ is in some sense proportional to $\\lambda^t$ (as shown in the lecture notes).\n",
    "\n",
    "Thus, if $\\lambda$ is close to $1$, then the convergence is slow, whereas if $\\lambda$ is small the convergence is faster.\n",
    "\n",
    "Note also that for periodic graphs, by Perron-Frobenius theorem have $\\lambda_n = -1$ (thus $\\lambda=1$), then the convergence to consensus is not achieved. This is coherent with the theory of consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**: note that every periodic strongly connected graph can be made periodic by adding at least a selfloop in the graph. Indeed, if a selfloop $(i,i)$ is added, then the period of node $i$ is 1. Since all the nodes in the same connected component have same period, then all the nodes have period $1$ and the graph is aperiodic.\n",
    "\n",
    "To avoid periodic graphs, sometimes it is useful to introduce the **lazy dynamics** obtained by replacing $P$ with \n",
    "\n",
    "$$\n",
    "\\frac{P+\\mathbf{I}}{2}\n",
    "$$\n",
    "\n",
    "This is equivalent to adding selfloops to each node in the graph with weight equivalent to the degree of the node itself.\n",
    "\n",
    "An interpretation for the lazy dynamics is that nodes have some inertia in the opinion. Instead of averaging over the opinions of the neighbors, they also take into account their opinion at the previous step. In fact,\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\frac{x_i(t) + \\sum_{j} P_{ij} x_j(t)}{2}.\n",
    "$$\n",
    "\n",
    "Let us go back to the initial periodic example, and show that the lazy dynamics converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(0,1),(1,2),(2,3),(3,0)])\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw(G, pos, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pl = P/2 + np.diag(np.ones(4))/2\n",
    "\n",
    "x = np.array([1, 0, 1, 0])\n",
    "\n",
    "for n in range(9):\n",
    "    x = Pl @ x\n",
    "print(\"x(10):\", x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How fast is the convergence of lazy dynamics?\n",
    "\n",
    "Note that $\\lambda_n(P_{lazy}) = 1/2 + \\lambda_n(P)/2 \\ge 1/2 + (-1/2) = 0$.\n",
    "\n",
    "Thus, $\\lambda = \\lambda_2$. \n",
    "\n",
    "In the lazy dynamics, the speed convergence is governed by $\\lambda_2$. Let us now define the relaxation time as\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{1}{1-\\lambda_2}\n",
    "$$\n",
    "\n",
    "For undirected graphs, $\\lambda_2$ may be related to the level of connectedness of the graph. In particular, if the graph is well connected, $\\lambda_2$ is smaller and the convergence to consensus is faster.\n",
    "\n",
    "We do not investigate the details on how to define \"connectedness\" of graphs in proper way here. However, we can verify by a simple example how connectedness of the graph influences the speed of convergence.\n",
    "\n",
    "Let us consider a **cycle graph** with 1000 nodes.\n",
    "\n",
    "For the cycle graph one can show (by the theory of circulant matrices) that\n",
    "\n",
    "$$\n",
    "\\lambda_2(P) = \\cos \\left(\\frac{2\\pi (n-1)}{n}\\right).\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to + \\infty} \\lambda(P_{lazy}) = \\frac{1}{2} + \\lim_{n \\to + \\infty} \\frac{1}{2} \\cos \\frac{2\\pi}{n} = 1-\\frac{\\pi}{n},\n",
    "$$\n",
    "\n",
    "and the relaxation time for the cycle is\n",
    "\n",
    "$$\n",
    "\\tau_{rel} = \\frac{n}{\\pi}.\n",
    "$$\n",
    "\n",
    "This means that the convergence is achieved exponentially with a rate that scales linearly with $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "Pl = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = Pl @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider the complete graph, which is the most connected graph by definition. For the complete graph,\n",
    "\n",
    "$$\n",
    "W=\\mathbf{1}\\mathbf{1}'-I.\n",
    "$$\n",
    "\n",
    "Since $\\mathbf{1}\\mathbf{1}'$ has equal columns, it has rank $1$. Thus $\\mathbf{1}\\mathbf{1}'$ has $n-1$ eigenvalues equal to $0$. The remaining eigenvalue can be found by using the fact that the sum of the eigenvalues is the trace of the matrix. Since $\\text{trace}(\\mathbf{1}\\mathbf{1}'-I)=0$, the spectrum of $W$ is\n",
    "\n",
    "$$\n",
    "\\sigma_W = \\{n-1,-1,\\cdots,-1\\}\n",
    "$$\n",
    "\n",
    "Since the complete graph is regular and every node has degree $n-1$, $P=W/(n-1)$\n",
    "Thus, the spectrum of $P$ is\n",
    "\n",
    "$$\n",
    "\\sigma_P = \\{1,-\\frac{1}{n-1},\\cdots,-\\frac{1}{n-1}\\},\n",
    "$$\n",
    "\n",
    "and $P_{lazy}$ has spectrum\n",
    "\n",
    "$$\n",
    "\\sigma_{P_{lazy}} = \\{1,-\\frac{1}{2(n-1)}+\\frac{1}{2},\\cdots,-\\frac{1}{2(n-1)}+\\frac{1}{2}\\}\n",
    "$$\n",
    "\n",
    "This implies that $\\lambda_2 = \\frac{1}{2}-\\frac{1}{2(n-1)} = \\frac{n-2}{2(n-1)}$ and the relaxation time for large $n$ in the complete graph tends\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to +\\infty} \\tau_{rel} = 2,\n",
    "$$\n",
    "\n",
    "i.e., even for infinite $n$ the relaxation time is finite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(1000)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# Construct lazy P\n",
    "Pl = P/2 + np.diag(np.ones(1000))/2\n",
    "\n",
    "# let us start with random initial conditions\n",
    "x = np.random.rand(1000)\n",
    "\n",
    "variance = np.var(x)\n",
    "n=0\n",
    "\n",
    "while (variance>0.001):\n",
    "    x = Pl @ x\n",
    "    n=n+1\n",
    "    variance = np.var(x)\n",
    "\n",
    "print('Number of iteration for convergence:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How fast is the convergence of (not lazy) averaging dynamics?\n",
    "\n",
    "In lazy dynamics the speed of convergence is described by $\\lambda_2$. In standard averaging dynamics, also $\\lambda_n$ plays a role. We recall indeed that the speed of convergence is described by\n",
    "\n",
    "$$\n",
    "\\lambda := \\max\\{\\lambda_2,|\\lambda_n|\\},\n",
    "$$\n",
    "\n",
    "where $\\lambda_n$ is the smallest eigenvalue of $P$.\n",
    "\n",
    "While $\\lambda_2$ is related to the level of connectedness of the graph, we shall see in a qualititive manner the role of $\\lambda_n$ by examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us construct a regular graph with 6m nodes, and degree of each node equal to m\n",
    "m = 5\n",
    "G = nx.cycle_graph(6*m)\n",
    "\n",
    "n_nodes = 6*m\n",
    "\n",
    "for n in range(6*m):\n",
    "    for i in range(m):\n",
    "        G.add_edge(n,(6*(i+1)+n-3) % 18)\n",
    "\n",
    "pos = nx.circular_layout(G)\n",
    "\n",
    "nx.draw(G,pos,with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,v = np.linalg.eig(P)\n",
    "w = w.real\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is bipartite, hence $-1$ is in the spectrum and the convergence to consensus is not guaranteed.\n",
    "\n",
    "Let us now add a single edge to break the periodicity while mantaining the total number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_edge(0,2)\n",
    "G.remove_edge(0,9)\n",
    "\n",
    "nx.draw(G,pos,with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "w,v = np.linalg.eig(P)\n",
    "w = w.real\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph is not periodic now. However, $|\\lambda_n| \\sim 1$, which implies that the convergence of the dynamics is slow. On the other hand, $\\lambda_2$ is \"small\" ($\\sim 1/2$), thus the lazy dynamics converges quickly.\n",
    "\n",
    "In some sense, $|\\lambda_n| \\sim 1$ reflects the fact that the graph is almost periodic. Let us see this with an example, by comparing the speed in convergence of the lazy dynamics and the standard dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a larger graph\n",
    "m = 50\n",
    "G = nx.cycle_graph(6*m)\n",
    "\n",
    "G.add_edge(0,2)\n",
    "\n",
    "n_nodes = 6*m\n",
    "\n",
    "for n in range(6*m):\n",
    "    for i in range(m):\n",
    "        G.add_edge(n,(6*(i+1)+n-3) % n_nodes)\n",
    "        \n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# let us start with random initial condition and standard dynamics\n",
    "x0 = np.random.rand(G.number_of_nodes())>1/2\n",
    "x = x0\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.00001):\n",
    "    x = P @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "    if t>100000:\n",
    "        t='inf'\n",
    "        break\n",
    "        \n",
    "print('Number of iterations for convergence of standard dynamics:', t)\n",
    "\n",
    "# same initial condition, lazy dynamics\n",
    "x = x0\n",
    "\n",
    "# Construct lazy P\n",
    "Pl = P/2 + np.diag(np.ones(G.number_of_nodes()))/2\n",
    "\n",
    "variance = np.var(x)\n",
    "t=0\n",
    "\n",
    "while (variance>0.00001):\n",
    "    x = Pl @ x\n",
    "    t=t+1\n",
    "    variance = np.var(x)\n",
    "    if t>100000:\n",
    "        t='inf'\n",
    "        break\n",
    "        \n",
    "print('Number of iterations for convergence of lazy dynamics:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wisdom of crowds\n",
    "Consider a graph, and assume that state of each node represents a noisy estimate of the real state $\\mu$, i.e.,\n",
    "\n",
    "$$\n",
    "x_i = \\mu + y_i,\n",
    "$$\n",
    "\n",
    "with $E[y_i]=0$, and the variance $\\sigma^2 (y_i) = \\sigma^2$ for each $i$.\n",
    "\n",
    "Assume that the graph is connected and aperiodic Eventually, the agents will reach consensus, i.e., $\\lim_{t \\to +\\infty} x(t) = \\alpha \\mathbf{1}$. \n",
    "\n",
    "**Question**: what is the consensus value $\\alpha$?\n",
    "\n",
    "Notice that $\\alpha = \\pi' (\\mu \\mathbf{1} + y) = \\mu + \\pi'y$, then\n",
    "\n",
    "$$\n",
    "E[\\alpha] = \\mu + \\pi' E[y] = \\mu\n",
    "$$\n",
    "\n",
    "so the final estimate of the network is unbiased. Moreover,\n",
    "\n",
    "$$\n",
    "\\quad \\sigma_{\\alpha}^2 = \\sigma^2 \\sum_{i} \\pi_i^2 < \\sigma^2,\n",
    "$$\n",
    "\n",
    "because $\\sum_{i} \\pi_i^2 <1$ unless the graph has a unique sink node. The interesting observation is that the estimate $\\alpha$ has a smaller variance than $\\sigma$, i.e., the crowd is able to reconstruct a more precise estimate of the real state than the single agents of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify this on a complete graph, where $\\pi_i = 1/n$, thus $\\sigma_\\alpha^2 = \\sigma^2/n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.complete_graph(100)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "# start with random initial states and run the dynamics 200 times\n",
    "# store in alfa_err the consensus values at each run\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns uniformly random values in [0,1], thus mu = 1/2\n",
    "    x = np.random.rand(100)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Variance of the node states:\", 1/12)\n",
    "print(\"Variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the variance of $\\alpha$ is about $1/100$ of the original variance.\n",
    "\n",
    "Note that $\\sum_{i} \\pi_i^2$ tends to 1 if one node has almost all the centrality, and is minimal when the nodes have the same centrality (as in the complete graph, or in the cycle graph). This implies that if a graph is more democratic, then the consensus algorithm leads to better estimates of the true state. If a few nodes have all the centralities, the consensus value is less reliable.\n",
    "\n",
    "Let us see this with a another example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with random initial states and run the dynamics\n",
    "alfa_err = np.zeros(200)\n",
    "\n",
    "for i in range(200):\n",
    "# rand returns random values in [0,1], thus \\mu = 1/2\n",
    "    x = np.random.rand(10)\n",
    "    var = np.var(x)\n",
    "    for n in range(500):\n",
    "        x = P @ x\n",
    "    alfa_err[i] = (1/2 - np.mean(x))*(1/2 - np.mean(x))\n",
    "\n",
    "print(\"Expected variance of the node states:\", 1/12)\n",
    "print(\"Empirical variance of the consensus state:\", np.mean(alfa_err), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this graph the consensus value is exactly the initial state of node $0$, because the condensantion graph has 1 sink only, which is node $0$.\n",
    "\n",
    "$$\n",
    "\\pi = \\delta^{(0)}.\n",
    "$$\n",
    "\n",
    "This graph is the opposite of the complete graph, in the sense that the invariant distribution centrality is totally on node $0$. Thus the variance of the consensus state equals the variance of the single node.\n",
    "\n",
    "Note that this argument holds independently of the size of the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application: distributed computation of average\n",
    "\n",
    "Let the node set describe a set of sensors that are deployed in some regions in order to collect measurements of some quantity of interest (for example, the temperature). \n",
    "\n",
    "Assume that these sensors have limited communication and computation capabilities that allow each of them to exchange information only with those other sensors that are close enough in space. \n",
    "\n",
    "Let the graph $G = (V, E)$ describe the pattern of closeness among the sensors $i$ and $j$ so that there is an undirected link between node $i$ and node $j$ if they can communicate to each other (possibly using link weights decreasing with distance). Then, one can design a distributed algorithm for computing the average of the sensor's measurements based on the averaging dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x_i(0)$ be the measurement of each node. \n",
    "\n",
    "We are interested in designing an iterative distributed algorithm that allows the nodes to compute\n",
    "\n",
    "$$\n",
    "x = \\frac{1}{n}\\sum_i x_i(0)\n",
    "$$\n",
    "\n",
    "**First attempt**: we run a consensus algorithm. Since the graph is undirected, $\\pi_i = \\frac{w_i}{\\sum_j w_j}$. Thus, the algorithm converges to a consensus $\\alpha \\mathbf{1}$ such that\n",
    "\n",
    "$$\n",
    "\\alpha = \\sum_i \\pi_i x_i(0) = \\sum_{i} \\frac{w_i}{w} x_i(0).\n",
    "$$\n",
    "\n",
    "If each edge knows its degree $w_i$, each node can rescale its initial state, i.e., $y_i(0) = \\frac{x_i(0)}{w_i}$. The consensus algorithm for the variable $y_i$ thus converges to\n",
    "\n",
    "$$\n",
    "\\alpha_y = \\sum_{i} \\frac{w_i}{w} y_i(0) = \\frac{1}{w} \\sum_{i} x_i(0).\n",
    "$$\n",
    "\n",
    "If we assume that each node knows the average degree of the network, thus\n",
    "\n",
    "$$\n",
    "x = \\alpha_y \\frac{w}{n} = \\alpha_y \\overline{w}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "\n",
    "# Fix node positions on all pictures according to spring layout\n",
    "pos = nx.spring_layout(G) \n",
    "nx.draw_networkx(G, pos)\n",
    "\n",
    "n_nodes = len(G)\n",
    "\n",
    "x = np.random.rand(n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us run the consensus algorithm for y\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "y = x/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    y = P @ y\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus on y\n",
    "print(\"average computed distributively\", y[0] * np.sum(degrees) / n_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works! Unfortunately, requiring that each node knows the average degree of the network is not realistic.\n",
    "\n",
    "However, there exists another way to solve the problem.\n",
    "\n",
    "**Second attempt**: we run a second averaging dynamics, with initial condition $z_i(0) = \\frac{1}{w_i}$.\n",
    "\n",
    "This converges to\n",
    "\n",
    "$$\n",
    "\\alpha_z = \\lim_{t \\to + \\infty} z_i(t) = \\sum_i z_i(0) \\frac{w_i}{w} = \\sum_{i} \\frac{1}{w} = \\frac{1}{\\overline{w}}\n",
    "$$\n",
    "\n",
    "By combining the two, each node can estimate the average estimate by \n",
    "\n",
    "$$\n",
    "\\frac{\\lim_{t \\to + \\infty} y_i(t)}{\\lim_{t \\to + \\infty} z_i(t)} = \\frac{\\alpha_y}{\\alpha_z} = \\frac{x}{\\overline{w}} \\cdot \\overline{w} = x.\n",
    "$$\n",
    "\n",
    "This method does not require any global knowledge on the network and it is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us implement this\n",
    "\n",
    "z = 1/degrees\n",
    "\n",
    "for t in range(1000):\n",
    "    z = P @ z\n",
    "\n",
    "print(\"average state:\", np.mean(x))\n",
    "# choose arbitrarly the first node, but all the nodes reach consensus both on y and z\n",
    "print(\"average computed distributively\", y[0] / z[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear averaging dynamics with stubborn agents\n",
    "We study how to simulate the linear averaging dynamics on graphs in presence of stubborn agents.\n",
    "\n",
    "We focus on the optimal placement problem, which consists of optimally chosing the position of a stubborn node on the graph in order to maximize its influence on the asymptotic outcome of the dynamics.\n",
    "\n",
    "Let us first summarize the theory in presence of stubborn agents.\n",
    "\n",
    "We are given a network, where the agents $V$ are divided in regular agents $R$ and stubborn agents $S$. The regular agents update their opinion $x(t)$ according to the standard DeGroot model, while the stubborn agents do not update their opinion $u(t) \\equiv u$.\n",
    "\n",
    "Let $Q=P|_{R \\times R}$ and $E=P|_{R \\times S}$.\n",
    "\n",
    "Thus, the dynamics for the regular agents read:\n",
    "\n",
    "$$\n",
    "x(t+1) = Qx(t) + Eu.\n",
    "$$\n",
    "\n",
    "Under some assumptions (see the lecture notes for details) the dynamics converges to \n",
    "\n",
    "$$\n",
    "x^* = (\\mathbf{I}-Q)^{-1}Eu.\n",
    "$$\n",
    "\n",
    "Note that, in contrast with the dynamics without stubborn nodes:\n",
    "- the asymptotic state is not a consensus;\n",
    "- the asymptotic state does not depend on the initial opinions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "We start by implementing the averaging dynamics with stubborn nodes. \n",
    "\n",
    "To illustrate this procedure, we will analyse the following example that involves a $3 \\times 4$ grid graph $\\mathcal G$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.generators.lattice.grid_graph(dim=[3,4])\n",
    "n_nodes = len(G)\n",
    "print(\"Number of nodes:\", n_nodes)\n",
    "\n",
    "# labels of nodes are couples: (column,row)\n",
    "nx.draw_spectral(G, with_labels=True)\n",
    "\n",
    "print(G.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary that maps the label of nodes  \n",
    "# (from (0,0) to (2,1)) to their index (from 0 to n_nodes-1)\n",
    "indices = dict()\n",
    "for i in range(n_nodes):\n",
    "    indices[list(G.nodes)[i]] = i\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_iter = 50;\n",
    "    \n",
    "# Stubborn and regular nodes\n",
    "stubborn = [(0,0), (3,2)];\n",
    "stubborn_id = [indices.get(key) for key in stubborn]\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "regular_id = [id for id in range(n_nodes) if id not in stubborn_id]\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to stubborn nodes\n",
    "u = [0,1]\n",
    "\n",
    "# P matrix\n",
    "A = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "A = A.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(A,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ A\n",
    "\n",
    "# Submatrices\n",
    "# Using ix_ one can construct index arrays that will \n",
    "# index a cross product. \n",
    "# a[np.ix_([1,3],[2,5])] returns the array [[a[1,2] a[1,5]], [a[3,2] a[3,5]]].\n",
    "Q = P[np.ix_(regular_id, regular_id)]\n",
    "E = P[np.ix_(regular_id, stubborn_id)]\n",
    "\n",
    "# Sample a random initial condition for regular nodes\n",
    "ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn_id,0] = u;\n",
    "x[regular_id,0] = ic;\n",
    "print(\"Initial state:\", x[:,0], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "    x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "print(\"Final state:\")\n",
    "x_final = x[:,n_iter-1]\n",
    "for key in indices.keys():\n",
    "    print(key, x_final[indices[key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(n_nodes):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = np.average(x_final)\n",
    "print(\"Average asymptotic opinion:\", average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the dynamics does not converge to consensus. Moreover, in contrast with averaging without input stubborn nodes, we can verify that the asymptotic equilibrium does not depend on the initial condition. Furthermore, the dynamics converge to an equilibrium even though the graph is periodic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample another random initial condition for regular nodes\n",
    "ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn_id,0] = u;\n",
    "x[regular_id,0] = ic;\n",
    "print(\"Initial state:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "    x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "print(\"Final state:\")\n",
    "x_final = x[:,n_iter-1]\n",
    "for key in indices.keys():\n",
    "    print(key, x_final[indices[key]])\n",
    "    \n",
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(n_nodes):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal placement of stubborn nodes\n",
    "Suppose that node $(0,0)$ is stubborn with opinion $u_{(0,0)}=0$. We want to find the optimal position $(i,j)$ of a stubborn node with opinion $1$ in order to maximize the asymptotic average opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very simple approach is to consider all possible positions $(i,j)$ and pick the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations\n",
    "n_iter = 50;\n",
    "\n",
    "# We will store final opinion vectors and \n",
    "# average of final opinions in dictionaries\n",
    "# where the key is the position (i,j) of the \n",
    "# 1-stubborn agent\n",
    "final_opinions = dict()\n",
    "average_opinion = dict() \n",
    "\n",
    "\n",
    "for (i,j) in G.nodes:\n",
    "    # Position (0,0) is occupied by the 0-stubborn node\n",
    "    if (i,j)==(0,0):\n",
    "        continue\n",
    "        \n",
    "    # Stubborn and regular nodes\n",
    "    stubborn = [(0,0), (i,j)];\n",
    "    stubborn_id = [indices.get(key) for key in stubborn]\n",
    "    regular = [node for node in G.nodes if node not in stubborn]\n",
    "    regular_id = [id for id in range(n_nodes) if id not in stubborn_id]\n",
    "    print(\"Stubborn nodes:\", stubborn)\n",
    "\n",
    "    # Input to stubborn nodes\n",
    "    u = [0,1]\n",
    "\n",
    "\n",
    "    # P matrix\n",
    "    A = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "    A = A.toarray() # convert A to a numpy array\n",
    "    degrees = np.sum(A,axis=1)\n",
    "    D = np.diag(degrees)\n",
    "    P = np.linalg.inv(D) @ A\n",
    "\n",
    "    # Submatrices\n",
    "    Q = P[np.ix_(regular_id, regular_id)]\n",
    "    E = P[np.ix_(regular_id, stubborn_id)]\n",
    "\n",
    "    # Sample a random initial condition for regular nodes\n",
    "    ic = np.random.uniform(0,1,len(regular))\n",
    "\n",
    "    # Set the initial condition for the dynamics\n",
    "    x = np.zeros((n_nodes,n_iter))\n",
    "    x[stubborn_id,0] = u;\n",
    "    x[regular_id,0] = ic;\n",
    "\n",
    "    for t in range(1,n_iter):\n",
    "        x[regular_id, t] = Q @ x[regular_id, t-1] + E @ x[stubborn_id, t-1]\n",
    "        x[stubborn_id, t] = x[stubborn_id, t-1];\n",
    "\n",
    "    final_opinions[(i,j)] = x[:,n_iter-1]\n",
    "    average_opinion[(i,j)] = np.average(final_opinions[(i,j)])\n",
    "    print(\"Average opinion:\", average_opinion[(i,j)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the dependence of the average asymptotic opinion on the position of the $1$-stubborn node we can plot the grid graph by setting each node's size and color according to the magnitude of the average asymptotic opinion when the $1$-stubborn is placed in such node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a dummy (0,0) entry to the dictionary\n",
    "# to make its size = n_nodes\n",
    "average_opinion[(0,0)] = 0\n",
    "\n",
    "plt.figure(1, figsize=(7,3))\n",
    "nx.draw(G, \n",
    "        pos = nx.spectral_layout(G),\n",
    "        with_labels=True, \n",
    "        node_size = [np.exp(10*average_opinion[node]) for node in G.nodes],\n",
    "        node_color= [average_opinion[node] for node in G.nodes],\n",
    "        font_size=8,\n",
    "        # node's colors are on the red scale\n",
    "        cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal placements of the 1-stubborn player are the maximizers of the final average opinion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the average opinion values from dict_values to numpy array\n",
    "avg = np.fromiter(average_opinion.values(),dtype=float)\n",
    "\n",
    "optimal_place = [place for place in average_opinion.keys() if average_opinion[place]==np.max(avg)]\n",
    "print(\"Optimal placements:\", optimal_place, \"\\n\")\n",
    "\n",
    "# print the final opinions under optimal placement\n",
    "opt_final = final_opinions.get(*optimal_place)\n",
    "print(\"Final opinions after optimal placement:\", opt_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the asymptotic opinions of the nodes when the stubborn is placed in (1,1)\n",
    "\n",
    "plt.figure(1, figsize=(7,3))\n",
    "nx.draw(G, \n",
    "        pos = nx.spectral_layout(G),\n",
    "        with_labels=True, \n",
    "        node_size = [np.exp(8*opt_final[indices.get(node)]) for node in G.nodes],\n",
    "        node_color= [opt_final[indices.get(node)] for node in G.nodes],\n",
    "        font_size=8,\n",
    "        # node's colors are on the red scale\n",
    "        cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Back to an old example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.cycle_graph(10)\n",
    "G = nx.Graph.to_directed(G)\n",
    "G.remove_edges_from([(0,1),(0,9)])\n",
    "G.add_edge(0,0)\n",
    "\n",
    "nx.draw(G, with_labels=True)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "\n",
    "# Construct P\n",
    "W = nx.adjacency_matrix(G) # -> return type is scipy.sparse.csr_matrix\n",
    "W = W.toarray() # convert A to a numpy array\n",
    "degrees = np.sum(W,axis=1)\n",
    "D = np.diag(degrees)\n",
    "P = np.linalg.inv(D) @ W\n",
    "\n",
    "n_iter = 100\n",
    "x = np.zeros((10,n_iter))\n",
    "\n",
    "# set initial condition (1,0,0,0,0,0,0,0,0,0)\n",
    "x[0,0] = 1\n",
    "\n",
    "# evolve the states\n",
    "for t in range(1,n_iter):\n",
    "    x[:,t] = P @ x[:,t-1]\n",
    "\n",
    "print(\"Average final opinions:\", np.mean(x[:,n_iter-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can prove that this is equivalent to having node 0 stubborn with opinion 1.\n",
    "\n",
    "Indeed, note that because of the topology of the graph, the opinion of node 0 is not influenced by anyone. The same dynamics can be obtained by assuming that node 0 is stubborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stubborn and regular nodes\n",
    "stubborn = [0];\n",
    "regular = [node for node in G.nodes if node not in stubborn]\n",
    "\n",
    "print(\"Stubborn nodes:\", stubborn, \"\\n\")\n",
    "print(\"Regular nodes:\", regular, \"\\n\")\n",
    "\n",
    "# Input to stubborn nodes\n",
    "u = [1]\n",
    "\n",
    "# Submatrices\n",
    "Q = P[np.ix_(regular, regular)]\n",
    "E = P[np.ix_(regular, stubborn)]\n",
    "\n",
    "# Set the initial condition for the dynamics\n",
    "x = np.zeros((n_nodes,n_iter))\n",
    "x[stubborn,0] = u;\n",
    "print(\"Initial condition:\", x[:,0], \"\\n\")\n",
    "\n",
    "# Evolve the opinion vector\n",
    "for t in range(1,n_iter):\n",
    "    x[regular, t] = Q @ x[regular, t-1] + E @ x[stubborn, t-1]\n",
    "    x[stubborn, t] = x[stubborn, t-1];\n",
    "\n",
    "x_final = x[:,n_iter-1]\n",
    "print(x_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(7,7))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for node in range(G.number_of_nodes()):\n",
    "    trajectory = x[node,:]\n",
    "    ax.plot(trajectory, label='node {0:d}'.format(node))\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same trajectory as before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A more general model: overview on Friedkin-Johnsen model\n",
    "The French-DeGroot dynamics can be generalized by taking into account that each agents is not completely regular or completely stubborn. The opinion of each agents is in part due to \"innate\" opinions, and in part due to influence of society.\n",
    "\n",
    "The following opinion dynamics model is known as Friedkin-Johnsen model.\n",
    "Here:\n",
    "- $x_i(t)$ is the opinion of the agent $i$;\n",
    "- $y_i$ is the innate opinion of agent $i$.\n",
    "- $\\alpha_i$ is its level of stubborness, i.e., the level of confidence in his/her opinion $y_i$.\n",
    "\n",
    "The dynamics reads:\n",
    "\n",
    "$$\n",
    "x_i(t+1) = \\alpha_i y_i + (1-\\alpha_i) \\sum_{j} P_{ij} x_j(t).\n",
    "$$\n",
    "\n",
    "If $\\alpha = \\mathbf{0}$, we get the French-DeGroot model without input.\n",
    "\n",
    "If $\\alpha \\in \\{0,1\\}^{V}$, we get the French-DeGroot model with stubborn nodes.\n",
    "\n",
    "As the French-DeGroot model with input, also the Friedkin-Johnsen dynamics converges to a non-consensus state, which depends on $\\alpha, y$, but not on the initial opinions $x(0)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
